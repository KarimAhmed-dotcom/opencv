{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:2581: error: (-27:Null pointer) NULL window: 'thresh_val' in function 'cvGetTrackbarPos'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-04aa305c7086>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateTrackbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"threshold\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"thresh_val\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetTrackbarPos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"threshold\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"thresh_val\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblur\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"thresh_val\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:2581: error: (-27:Null pointer) NULL window: 'thresh_val' in function 'cvGetTrackbarPos'\n"
     ]
    }
   ],
   "source": [
    "# trackbar to know the optimal threshold \n",
    "import cv2\n",
    "import numpy as np \n",
    "cap=cv2.VideoCapture(\"peopl.mp4\")\n",
    "ret,frame1=cap.read() \n",
    "ret,frame2=cap.read()\n",
    "diff=cv2.absdiff(frame1,frame2)\n",
    "gray=cv2.cvtColor(diff,cv2.COLOR_BGR2GRAY) \n",
    "blur=cv2.GaussianBlur(gray,(5,5),0) \n",
    "def nothing(x) : \n",
    "    pass\n",
    "cv2.namedWindow(\"thresh_val\")\n",
    "cv2.createTrackbar(\"threshold\",\"thresh_val\",0,100,nothing)\n",
    "while(1) : \n",
    "    value=cv2.getTrackbarPos(\"threshold\",\"thresh_val\")\n",
    "    _,threshold=cv2.threshold(blur,value,255,cv2.THRESH_BINARY)\n",
    "    cv2.imshow(\"thresh_val\",threshold)\n",
    "    if cv2.waitKey(1) == 27 : \n",
    "        break \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trackbar to know the optimal min_max values for canny edge detection \n",
    "import cv2\n",
    "import numpy as np \n",
    "cap=cv2.VideoCapture(\"peopl.mp4\")\n",
    "ret,frame1=cap.read() \n",
    "ret,frame2=cap.read()\n",
    "diff=cv2.absdiff(frame1,frame2)\n",
    "blur=cv2.GaussianBlur(diff,(5,5),0) \n",
    "\n",
    "def nothing(x) : \n",
    "    pass\n",
    "cv2.namedWindow(\"canny\")\n",
    "cv2.createTrackbar(\"min_value\",\"canny\",0,200,nothing)\n",
    "cv2.createTrackbar(\"max_value\",\"canny\",0,200,nothing)\n",
    "while(1) : \n",
    "    min_value=cv2.getTrackbarPos(\"min_value\",\"canny\")\n",
    "    max_value=cv2.getTrackbarPos(\"max_value\",\"canny\")\n",
    "    edges=cv2.Canny(blur,min_value,max_value,(3,3))\n",
    "    cv2.imshow(\"canny\",edges)\n",
    "    if cv2.waitKey(1) == 27 : \n",
    "        break \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# people tracking with threshold\n",
    "import cv2 \n",
    "import numpy as np \n",
    "\n",
    "cap=cv2.VideoCapture(\"peopl.mp4\")\n",
    "\n",
    "forcc=cv2.VideoWriter_fourcc(*'MP4V') \n",
    "\n",
    "out=cv2.VideoWriter(\"E:\\\\faculty3\\\\computer vision\\\\project\\\\people1.mp4\",forcc,5.0,(1280,720))\n",
    "\n",
    "frame_width=cap.get(3)\n",
    "frame_height=cap.get(4)\n",
    "\n",
    "ret,frame1=cap.read() \n",
    "ret,frame2=cap.read() \n",
    "while cap.isOpened() : \n",
    "    diff = cv2.absdiff(frame1, frame2)\n",
    "    gray=cv2.cvtColor(diff,cv2.COLOR_BGR2GRAY)\n",
    "    blur=cv2.GaussianBlur(gray,(5,5),0)\n",
    "    _,threshold=cv2.threshold(blur,22,255,cv2.THRESH_BINARY)\n",
    "    dilated=cv2.dilate(threshold,None,iterations=3) \n",
    "    contours,_=cv2.findContours(dilated,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "    #draw=cv2.drawContours(frame1,contours,-1,(0,255,0),3) \n",
    "    i=1\n",
    "    for contour in contours : \n",
    "        (x,y,w,h)=cv2.boundingRect(contour) \n",
    "        \n",
    "        if cv2.contourArea(contour) < 900 :\n",
    "            continue\n",
    "        i=i+1   \n",
    "        cv2.rectangle(frame1,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        num_contours=len(contours)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(frame1, \"number of people is : %s\"%str(i), (10, 20), font,\n",
    "                    1, (0, 0, 255), 3)\n",
    "        \n",
    "    image=cv2.resize(frame1,(1280,720))\n",
    "    out.write(image) \n",
    "    cv2.imshow(\"motion detection\",frame1) \n",
    "        \n",
    "    frame1=frame2 \n",
    "    ret,frame2=cap.read() \n",
    "    \n",
    "    if cv2.waitKey(40) == 27 : \n",
    "        break   \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# people tracking with canny edge detection\n",
    "import cv2 \n",
    "import numpy as np \n",
    "\n",
    "cap=cv2.VideoCapture(\"peopl.mp4\")\n",
    "\n",
    "fourcc= cv2.VideoWriter_fourcc('X','V','I','D')\n",
    "\n",
    "out=cv2.VideoWriter(\"E:\\\\faculty3\\\\computer vision\\\\project\\\\people1.mp4\",fourcc,5.0,(1280,720))\n",
    "\n",
    "frame_width=cap.get(3)\n",
    "frame_height=cap.get(4)\n",
    "\n",
    "ret,frame1=cap.read() \n",
    "ret,frame2=cap.read() \n",
    "while cap.isOpened() : \n",
    "    diff = cv2.absdiff(frame1, frame2)\n",
    "    blur=cv2.GaussianBlur(diff,(5,5),0)\n",
    "    edges=cv2.Canny(blur,122,5,(3,3))\n",
    "    dilated=cv2.dilate(edges,None,iterations=3) \n",
    "    contours,_=cv2.findContours(dilated,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "    #draw=cv2.drawContours(frame1,contours,-1,(0,255,0),3) \n",
    "    i=1\n",
    "    for contour in contours : \n",
    "        (x,y,w,h)=cv2.boundingRect(contour) \n",
    "        \n",
    "        if cv2.contourArea(contour) < 900 :\n",
    "            continue\n",
    "        i=i+1\n",
    "        cv2.rectangle(frame1,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        num_contours=len(contours)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(frame1, \"number of people is : %s\"%str(i), (10, 20), font,\n",
    "                    1, (0, 0, 255), 3)\n",
    "        \n",
    "    image=cv2.resize(frame1,(1280,720))\n",
    "    out.write(image) \n",
    "    cv2.imshow(\"motion detection\",frame1) \n",
    "    frame1=frame2 \n",
    "    ret,frame2=cap.read() \n",
    "    \n",
    "    if cv2.waitKey(100) == 27 : \n",
    "        break   \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
